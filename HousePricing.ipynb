{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from src.normal_equation import compute_theta\n","from src.gradient_descent import descent\n","from src.feature_normalize import normalize\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from IPython import get_ipython\n","get_ipython().run_line_magic('matplotlib', 'inline')\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # House Pricing\n"," This was an assignment on Andrew Ng's Machine Learning Course. I've already done the exercise in Octave, this project is to help me get familiar with the different libraries in Python.\n"," ## Problem\n"," Suppose you are selling your house and you want to know what a good market price would be. One way to do this is to first collect information on recent houses sold and make a model of housing prices.\n"," ## Data\n"," The file **data.txt** contains a training set of housing prices in Port- land, Oregon. The first column is the size of the house (in square feet), the second column is the number of bedrooms, and the third column is the price of the house."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"   Size  Bedrooms   Price\n0  2104         3  399900\n1  1600         3  329900\n2  2400         3  369000\n3  1416         2  232000\n4  3000         4  539900","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Size</th>\n      <th>Bedrooms</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2104</td>\n      <td>3</td>\n      <td>399900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600</td>\n      <td>3</td>\n      <td>329900</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2400</td>\n      <td>3</td>\n      <td>369000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1416</td>\n      <td>2</td>\n      <td>232000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000</td>\n      <td>4</td>\n      <td>539900</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}],"source":["df = pd.read_csv('data/data.txt', names=['Size', 'Bedrooms', 'Price'])\n","df.head()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Feature Normalization\n"," Looking at the data, it is clear that there's a huge difference in the two features. This will have a significant effect in running Gradient Descent, remember that the formula requires minimizing the product of features and a value theta. The algorithm might think that the feature *Size* have a significantly higher effect in Price compared to the *Number of Bedrooms*\n","\n"," This can be addressed by scaling the features using the *mean* and *standard deviations*.\n","\n"," First create an X matrix containing all the samples in rows and its features in columns. Put the actual price values in a separate Y vector."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Create the X-matrix\n","X = df.iloc[:, :len(df.columns)-1].to_numpy()\n","# Create the Y-matrix\n","Y = df.iloc[:, -1].to_numpy()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Using the *feature_normalize* script, pass in the X matrix. The script will handle all feature scaling using each features *mean* and *standard deviation*.\n","\n"," Store the result in a separate matrix, in case the original X values are needed.\n","\n"," ```python\n"," def normalize(X: np.array):\n","     mu = np.mean(X, axis=0)\n","     std = np.std(X, axis=0, ddof=1)\n","     return [(X - mu) / std, mu, std]\n"," ```"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["X_norm, mu, std = normalize(X)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Gradient Descent\n"," After the features have been normalized, prepare the variables required to perform Gradient Descent.\n","\n"," First, add in the 1's column for the X-intercept. Initalized the theta values to 0. Make sure to experiment with the learning rate to see the best result.\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["m, n = X.shape\n","X_1 = np.c_[np.ones(m), X_norm]\n","alpha = 0.03\n","iterations = 400\n","theta = np.zeros(n + 1)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Run Linear Regression with Gradient Descent using the *gradient_descent* script.\n"," This can now then minimize the JCost function using the theta values.\n","\n"," ```python\n"," def descent(X: np.array, Y: np.array, theta: np.array, alpha):\n","     m = len(Y)\n","     h = X.dot(theta)\n","     theta = theta - ((h - Y).dot(X) * (alpha / m))\n","     return theta\n"," ```"]},{"cell_type":"code","execution_count":6,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Computed theta (Gradient Descent): [340410.91897274 110308.11337059  -6326.5381075 ]\n"}],"source":["for i in range(iterations):\n","    theta = descent(X_1, Y, theta, alpha)\n","print(f'Computed theta (Gradient Descent): {theta}')\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Normal Equation\n"," The computed thetas can now then be used to predict house prices given it's size and number of bedrooms.\n","\n"," In this section, Normal Equation will be demonstrated. It is a form of Linear Regression that doesn't use batch updates like Gradient Descent.\n"," There are several pros and cons to the two algorithms, ultimately it will vary from use case to use case.\n","\n"," Here is the closed form equation of Linear Regression:\n"," ![normal_equation](./docs/normal_equation.png)\n","\n"," Using the *normal_equation* script, import the *compute_theta* function. This function will only require the feature matrix X and Y.\n","\n"," ```python\n"," def compute_theta(X: np.array, Y: np.array):\n","     xtx_inv = np.linalg.pinv(X.transpose().dot(X))\n","     xty = X.transpose().dot(Y)\n","     return xtx_inv.dot(xty)\n"," ```"]},{"cell_type":"code","execution_count":7,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Computed theta (Normal Equation): [89597.90954361   139.21067402 -8738.01911255]\n"}],"source":["X_1_norm = np.c_[np.ones(m), X]\n","theta_normal = compute_theta(X_1_norm, Y)\n","print(f'Computed theta (Normal Equation): {theta_normal}')\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Prediction\n"," Using the two theta values computed, we can now predict the price for a house given it's size and number of bedrooms.\n","\n"," When using Gradient Descent, it's important to remember to normalize the feature parameters first before making a prediction."]},{"cell_type":"code","execution_count":8,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Price of House with 1650 sqr feet and 3 br\n\nGradient Descent: $293,149.99\nNormal Equation: $293,081.46\n"}],"source":["house_size = 1650\n","house_rooms = 3\n","\n","features = np.array([house_size, house_rooms])\n","scaled = (features - mu) / std\n","x_gradient = np.append([1], scaled)\n","x_normal = np.array([1, house_size, house_rooms])\n","\n","price_gradient = x_gradient.dot(theta)\n","price_normal = x_normal.dot(theta_normal)\n","\n","print(f'Price of House with {house_size} sqr feet and {house_rooms} br\\n')\n","print(f'Gradient Descent: ${price_gradient:,.2f}')\n","print(f'Normal Equation: ${price_normal:,.2f}')\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}